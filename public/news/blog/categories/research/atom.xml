<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: research | Infonomics Blog]]></title>
  <link href="http://infonomics.ltd.uk/news/blog/categories/research/atom.xml" rel="self"/>
  <link href="http://infonomics.ltd.uk/news/"/>
  <updated>2014-05-08T10:28:50+02:00</updated>
  <id>http://infonomics.ltd.uk/news/</id>
  <author>
    <name><![CDATA[Robin Gower]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[LEP Economic Profiles - How do local assets affect productivity]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2014/01/17/lep-economic-profiles-how-do-local-assets-affect-productivity/"/>
    <updated>2014-01-17T08:31:00+01:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2014/01/17/lep-economic-profiles-how-do-local-assets-affect-productivity</id>
    <content type="html"><![CDATA[<p>Jim Twomey of <a href="http://www.pion-economics.co.uk/">Pion Economics</a> put together a fascinating statistical analysis of Local Economic Partnership areas. I offered to visualise the findings, and here are the results (click through for the interactive visualisation):</p>

<p><a href="http://infonomics.ltd.uk/lep-profiles/index.html"><img src="/images/post_images/lep_analysis_screenshot.png" title="LEP Analysis Screenshot" ></a></p>

<!-- more -->


<p>The statistical techqniue is quite advanced, and I&rsquo;m still searching for a simple way to explain it. The objective is to describe differences in productivity in terms of the attributes of each place so that performance may be understood, and insights found into what a place might need to improve. First the attributes are gathered together into asset groups that correlate closely with one another (factor analysis). Then the level of these 8 groups is compared against local economic productivity to estimate the contribution of those assets to performance. More information on the technique may be found in the <a href="http://pion-economics.co.uk/cms/resources/uploads/File/LEP_document.pdf">Developing LEP Economies Report</a>.</p>

<p>The interactive visualisation is designed to provide both an overview of the patterns across LEP areas and a means of finding the results that apply to each LEP individually. The analysis presents three panels. The map on the left is for navigation. By hovering over a given place, the relevant LEP profile will be selected. On the right, the top panel presents all LEPs ordered by productivity level and the bottom panel the contribution of assets. Each chart shows the overall range of values for context, with the selected LEP area highlighted in bold. You may also navigate using the top right panel.</p>

<p>The interactive element allows you to explore patterns and relationships. Try, for example, drawing your cursor from the periphery of England in towards London. Note how the level of productivity and the contribution of the Access asset group changes. Try comparing rural and urban areas.</p>

<p>We found that this visualisation technique makes it far more efficient to present research findings (displaying 39 profiles in one graphic) and allows additional insights to be discovered through interactive exploration.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to choose a Sample Size]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2013/10/18/how-to-choose-a-sample-size/"/>
    <updated>2013-10-18T09:26:00+02:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2013/10/18/how-to-choose-a-sample-size</id>
    <content type="html"><![CDATA[<p>I&rsquo;m often asked to provide advice on this question. The short answer is usually &ldquo;it depends&rdquo;. This is the longer answer that explains what it depends on!</p>

<p>The size of a sample doesn&rsquo;t need to be as large people usually think. The sample size doesn&rsquo;t actually depend upon the population size (i.e. the things &ndash; individuals, organisations, or projects &ndash; that the sample is supposed to represent). Indeed National opinion polls usually include no more than 1,000 responses (although they do require an <a href="http://en.wikipedia.org/wiki/Sampling_bias#Historical_examples">unbiased sample</a>).</p>

<p>So what does sample size depend upon..?</p>

<!-- more -->


<h2>Why choosing a sample size is important</h2>

<p>A sample is a subset of a population that you wish to study. A sample is typically chosen for research because it is too difficult or expensive to talk to the whole population. Fortunately statistical theory demonstrates that it is possible for responses taken from a sample to represent a wider population.</p>

<p>This post explains some of things to consider when choosing a representative sample.</p>

<h2>Total sample size</h2>

<p>The choice of overall sample size is driven by three statistical considerations</p>

<ul>
<li>what effect size you want to capture (i.e. the expected difference between the things you&rsquo;re comparing),</li>
<li>how willing you are to miss effects that are present, and</li>
<li>how willing you are to mistakenly identify effects that aren&rsquo;t present.</li>
</ul>


<p>We can set the latter two according to statistical convention (significance level of 95%, and a statistical power of 80%). Effect size really depends upon the context.</p>

<p>The main unknown here will be the standard deviation &ndash; that is to say the extent to which the things you&rsquo;re measuring vary from case-to-case. This, of course, determines the degree to which we can draw conclusions about the whole population by looking at a sample.</p>

<p>We define the effect size relative to the standard deviation. The larger the effect size, the smaller the sample needed to detect it. Drawing on social research, Cohen suggests that 20%, 50%, and 80% (of the standard deviation) represent small, medium, and large effect sizes respectively.</p>

<h2>Representativeness of sub-groups</h2>

<p>There are a couple of issues here. First, the overall results should be representative (you don&rsquo;t want to miss-out certain groups) and unbiased (if the sample structure doesn&rsquo;t match the proportion of the overall population the results will need to be weighted). Second, you might want to compare the results of the sub-groups (e.g. treatment vs control groups, cohorts by gender/ age/ ethncitiy, or to see if results change over time/ by location).</p>

<p>Bear in mind the above discussion on sample sizes. The rule of thumb value for sub-samples is to have 30 responses &ndash; is consistent with an effect size of 73%. This would, of course, be exhaustive for some of the smaller sub-groups. You may need to combine sub-groups or deal with this variability in the analysis rather than in the sample design &ndash; e.g. removing outliers after the responses have been gathered). You might aim for 30 responses among the larger groups but relax this for smaller ones.</p>

<h2>Response rates</h2>

<p>This depends on how and who contacts the projects. Fortunately, as a funder you&rsquo;re likely to have their attention! In my experience of contacting beneficiaries on behalf of public/ social projects, a 30% response rate is good going. Don&rsquo;t be surprised if you receive a response rate lower than 1% for an email survey (although the ease of contacting a wide range should mean this is still an effective method). I&rsquo;d aim to contact about 5 times as many people as you need responses.</p>

<p>The overall decision on sample size ought to take into account the cost and difficulty of acquiring responses and the observed variability of responses. You might want to bootstrap the process by running an initial small sample that would serve to identify whether further booster samples are required (e.g. &ldquo;the overall result is satisfactory but we&rsquo;re concerned about the apparent discrepancy among very large projects so they&rsquo;ll be the subject of further research&rdquo;). Bear in mind that this is by no means a precise science and this guidance should be considered in the context of practical concerns. Perhaps the most useful contribution of statistical advice &ndash; rather than identifying a magic number &ndash; is to help you to understand the overall patterns (variability matters, diminishing returns apply, very large/ small projects might need to be considered separately).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pay for outcomes not activity]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2012/12/19/pay-for-outcomes-not-activity/"/>
    <updated>2012-12-19T20:37:00+01:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2012/12/19/pay-for-outcomes-not-activity</id>
    <content type="html"><![CDATA[<p>Commission outcomes not activity.</p>

<p>As part of my contribution to <a href="http://thecreativeexchange.org/">The Creative Exchange</a> I attended a workshop on Public Service Innovation and Democracy. Through the course of discussion we soon discovered that several attendees working in creative and service sectors experience a common problem with tendering &ndash; that the organisation running the procurement often has very fixed ideas about what they want to buy. There was general agreement that this tendency to be very specific didn&rsquo;t leave much room for imagniation and innovation.</p>

<p>The outcome of our discussion was a proposal to explore a new approach to commissioning digital and creative services.</p>

<!--more-->


<p>Here&rsquo;s a quote from the terms of reference:</p>

<blockquote><p>The standard tendering model is not effective in the contemporary cultural and creative sector:</p>

<ul>
<li><strong>Premature-specification</strong>: The traditional model, with a specification of how or what should be delivered, is appropriate to homogenous services or goods where tenders must meet requirements that can be determined before the competitive procedure. Creative services, by contrast, are constrained if the method is defined in advance. Instead the commissioner should focus on explaining their aims and objectives and allow the competing suppliers to imagine and suggest what and how these should be delivered.</li>
<li><strong>Speculative work</strong>: procurement of creative services can involve requests for ideas, examples, or other forms of speculative work like open competitions. This involves considerable upfront investment from suppliers, the intellectual property rights for which cannot be protected. Indeed the award of a contract is not guaranteed overall (let alone to any given supplier). Suppliers are at a significant disadvantage in this commissioning model and the incentives for participation are weak.</li>
<li><strong>Risk-aversion</strong>: The priority in procurement is often to minimise risk rather than maximise value-for-money. This can lead to a bias towards larger established firms at the expense of SMEs and of innovation.</li>
<li><strong>Administrative-burden</strong>: public tenders often involve lengthy pre-qualification processes and masses of paperwork (often owing to risk aversion as above). This burden weighs disproportionately heavily on SMEs who may not have the resources to respond or for whom such requirements may be irrelevant (i.e. a freelance designer working from her kitchen probably doesn’t need ISO compliant Health and Safety policy).</li>
</ul>


<p><cite>Alpha Procurement Proposal</cite></p></blockquote>

<p>The project is at a very early stage but I&rsquo;ll provide an update once we&rsquo;re underway.</p>

<p>If you&rsquo;ve any thoughts by all means let us know in the comments&hellip;</p>
]]></content>
  </entry>
  
</feed>
