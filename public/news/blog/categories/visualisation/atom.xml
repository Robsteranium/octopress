<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: visualisation | Infonomics Blog]]></title>
  <link href="http://infonomics.ltd.uk/news/blog/categories/visualisation/atom.xml" rel="self"/>
  <link href="http://infonomics.ltd.uk/news/"/>
  <updated>2014-01-20T09:58:47+01:00</updated>
  <id>http://infonomics.ltd.uk/news/</id>
  <author>
    <name><![CDATA[Robin Gower]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Sonification and Auditory Display Primer]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2014/01/19/sonification-and-auditory-display-primer/"/>
    <updated>2014-01-19T18:36:00+01:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2014/01/19/sonification-and-auditory-display-primer</id>
    <content type="html"><![CDATA[<p>An auditory display uses sound to convery information. Sonification is defined as a type auditory display that uses non-speech audio, rendering sound in response to data and interaction.</p>

<p>This post provides a brief introduction to sonfication based upon <a href="http://sonification.de/handbook/index.php/chapters/chapter2/">Chapter 2</a> of the <a href="http://sonification.de/handbook/">Sonification Handbook</a>.</p>

<div class="well">
  <p>A <a href="http://sonify.psych.gatech.edu/research/soundscapes/">soundscape mapping a stock market index to ecological sounds</a>. As the index rises, bird calls, crickets, frogs, and other forest sounds are added. As the index falls, rain and thunder are heard. The soundscape is designed to be monitoring peripherally and not to be intrusive.</p>
  <p><audio src="http://sonify.psych.gatech.edu/research/soundscapes/sounds/fullsample01.mp3" type="audio/mpeg" controls></audio></p>
</div>




<!--more-->


<h2>Why sonification is useful</h2>

<div class="well callout">
  <p><a href="http://silentlistening.wordpress.com/2008/05/09/dispersion-of-sound-waves-in-ice-sheets/">Andreas Bick's field recording of ice cracks</a> is already in the audible range. The recording exhibits the difference between the transmission of the echoes through ice and water.</p>
  <p><audio src="http://silentlistening.files.wordpress.com/2008/04/frost-pattern.mp3" controls></audio></p>
</div>


<ul>
<li>the human auditory system is good at recognising temporal changes or patterns</li>
<li>the operator may not always be able to see a visual display

<ul>
<li>the content does not require constant observation such as warning alarms</li>
<li>an existing visual system may be overloaded</li>
<li>the perceiver may be visually impaired</li>
</ul>
</li>
<li>the data is verbal-categorical, has a high number of dimensions, or requires rapid detection</li>
<li>because the rise of mobile devices mean smaller screens and less room for visual displays</li>
</ul>


<h2>Use cases</h2>

<div class="well callout">
  <p>An auditory menu designed for use by drivers. You can hear the user scrolling through an address book. The spindex cues give an overview of alphabetical position, with slower navigation triggering spearcons for each contact.</p>
  <p><audio src="http://sonification.de/handbook/media/chapter2/SHB-S2.2.mp3" type="audio/mpeg" controls></audio></p>
</div>


<ul>
<li>alerts and notifications (indicating an occurance)</li>
<li>alarms and warnings (indicating an adverse occurance, perhaps requiring an urgent response)</li>
<li>status and progress indicators</li>
<li>data exploration and auditory graphs</li>
<li>art, entertainment, sport and leisure</li>
</ul>


<h2>Types of Sonification</h2>

<h3>Interaction</h3>

<div class="well callout">
<p>
<img src="http://infonomics.ltd.uk/news/images/post_images/tectonics.png" alt="Tectonics thumbnail" />
Florian Dombois' audification of <a href="http://www.auditory-seismology.org/version2004/tectonics.html">Plate Tectonics</a> demonstrates the difference between the plop of the parting Atlantic ocean plates and the crack of the plates drifting against each other).
</p>
</div>


<p>At one end of the scale, there are non-interactive sonifications that once triggered play in their entirety as a concert or a tour around the information. This has parallels with the direction instruction method of teaching whereby an existing conclusion or viewpoint is demonstrated.</p>

<p>At the other end of the scale, there are user-initiated sonifications that require the user to engage in a conversation. This has parallels with the enquiry-based learning method which begins with questions, problems, or scenarios allowing knowledge to be discovered through exploration.</p>

<p>Somewhere in between lies the facility for manipulation of the sonification at basic level &ndash; controlling the speed, pausing, fast-forwarding, and/ or rewinding.</p>

<h3>Methods</h3>

<ul>
<li><em>Audification</em> transforms periodic or other data that has a waveform structure into the audible range.</li>
<li><em>Parameter Mapping Sonification</em> extends this to other data forms, mapping a data dimension to an accoustic dimension</li>
<li><em>Model-based Sonfication</em> emerges from the interaction of a user with an instrument so that the data structure is understood through the sonic responses of a virtual object.</li>
</ul>


<p>An <em>auditory icon</em> represents something and bears an analogous resemblence so that it should be understood without explanation. An <em>earcon</em> is more symbolic, and has and arbitrary mapping of sound to meaning. Although Earcons are more flexible, they may have to be learned. The <em>spearcon</em>, a speech earcon, has the potential to offer the best of both worlds &ndash; flexibility and understandability. A <em>spindex</em> is a set of brief speech sounds that are used to navigate a long menu.</p>

<h3>Design Considerations</h3>

<p>Qualitative data may be better represented by dimensions of sound that are perceived as categorical, such as timbre. Whereas pitch or loudness, which are more continuous, may be better for ratio or interval data.</p>

<p>The polarity of the mapping matters. In one study, listeners agreed that pitch should increase with increasing temperature but that it should decrease with increasing size.</p>

<p>While the human hearing range stretches from about 20 Hz to 20,000 Hz, it may be more successful to scale data to the range where hearing is most sensitive, for example between 1000-5000 Hz.</p>

<p>A musical model, for example the notes on a piano, can provide a scale with perceptually equal steps. This convenience does come at the cost of resolution. A MIDI display using only notes 35-100 provides 65 points whereas a microtonal scale would be comparatively infinite.</p>

<p>Monitoring tasks require that the listener has a priori knowledge of a particular template so that they may recognise a sound and it&rsquo;s meaning.</p>

<p>Concurrent presentation of multiple data streams requires that the user be able to segregate the streams. Differences in timbre (musical instrument) or spatial separation (stereo panning) have been used for this purpose.</p>

<p>Context cues can aid perception. Like tick marks on the axis of a visual graph, a series of clicks can help the user keep track of time and a repeating reference tone can help with point estimation.</p>

<div class="well">
<p>The <a href="http://www.sonifyer.org/sound/erdbewegung/progress/?id=38">Sonification of Tohoku Earthquake</a> accelerates seismic activiy by a factor of 1440 to bring signal into the audible range.</a></p>
<div id="ytplayer"></div>
<script>
  // Load the IFrame Player API code asynchronously.
  var tag = document.createElement('script');
  tag.src = "https://www.youtube.com/player_api";
  var firstScriptTag = document.getElementsByTagName('script')[0];
  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

  // Replace the 'ytplayer' element with an <iframe> and
  // YouTube player after the API code downloads.
  var player;
  function onYouTubePlayerAPIReady() {
    player = new YT.Player('ytplayer', {
      height: '390',
      width: '640',
      videoId: '3PJxUPvz9Oo'
    });
  }
</script>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LEP Economic Profiles - How do local assets affect productivity]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2014/01/17/lep-economic-profiles-how-do-local-assets-affect-productivity/"/>
    <updated>2014-01-17T08:31:00+01:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2014/01/17/lep-economic-profiles-how-do-local-assets-affect-productivity</id>
    <content type="html"><![CDATA[<p>Jim Twomey of <a href="http://www.pion-economics.co.uk/">Pion Economics</a> put together a fascinating statistical analysis of Local Economic Partnership areas. I offered to visualise the findings, and here are the results (click through for the interactive visualisation):</p>

<p><a href="http://infonomics.ltd.uk/lep-profiles/index.html"><img src="/images/post_images/lep_analysis_screenshot.png" title="LEP Analysis Screenshot" ></a></p>

<!-- more -->


<p>The statistical techqniue is quite advanced, and I&rsquo;m still searching for a simple way to explain it. The objective is to describe differences in productivity in terms of the attributes of each place so that performance may be understood, and insights found into what a place might need to improve. First the attributes are gathered together into asset groups that correlate closely with one another (factor analysis). Then the level of these 8 groups is compared against local economic productivity to estimate the contribution of those assets to performance. More information on the technique may be found in the <a href="http://pion-economics.co.uk/cms/resources/uploads/File/LEP_document.pdf">Developing LEP Economies Report</a>.</p>

<p>The interactive visualisation is designed to provide both an overview of the patterns across LEP areas and a means of finding the results that apply to each LEP individually. The analysis presents three panels. The map on the left is for navigation. By hovering over a given place, the relevant LEP profile will be selected. On the right, the top panel presents all LEPs ordered by productivity level and the bottom panel the contribution of assets. Each chart shows the overall range of values for context, with the selected LEP area highlighted in bold. You may also navigate using the top right panel.</p>

<p>The interactive element allows you to explore patterns and relationships. Try, for example, drawing your cursor from the periphery of England in towards London. Note how the level of productivity and the contribution of the Access asset group changes. Try comparing rural and urban areas.</p>

<p>We found that this visualisation technique makes it far more efficient to present research findings (displaying 39 profiles in one graphic) and allows additional insights to be discovered through interactive exploration.</p>
]]></content>
  </entry>
  
</feed>
