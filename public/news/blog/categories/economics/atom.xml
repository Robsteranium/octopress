<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: economics | Infonomics Blog]]></title>
  <link href="http://infonomics.ltd.uk/news/blog/categories/economics/atom.xml" rel="self"/>
  <link href="http://infonomics.ltd.uk/news/"/>
  <updated>2015-02-20T17:22:06+00:00</updated>
  <id>http://infonomics.ltd.uk/news/</id>
  <author>
    <name><![CDATA[Robin Gower]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Open Data Business Models]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2013/03/01/open-data-business-models/"/>
    <updated>2013-03-01T19:16:00+00:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2013/03/01/open-data-business-models</id>
    <content type="html"><![CDATA[<p>Data doesn&rsquo;t make for a good tradable commodity, as discussed in a previous post on the <a href="/blog/2012/10/25/the-economics-of-open-data">Economics of Open Data</a>. Because of these market failures, there&rsquo;s a strong business case for the public sector to open data.
But what about commercial business models for open data? This post explains why it&rsquo;s not just the public sector who ought to pay attention to this opportunity.
The post is split into three topics: opening data that you own (why data assets are more valuable to you open), using open data (how to exploit your or someone else&rsquo;s open data) and commercial models (how to get paid in the process).</p>

<!--more-->


<h2>Opening your data</h2>

<p>Why should you open your data? Here are a few reasons:</p>

<ul>
<li>Network effects</li>
<li>Risk mitigation</li>
<li>Reputation</li>
<li>Attention</li>
</ul>


<h3>Network effects &ndash; Open is more exploitable</h3>

<p>There is a much greater potential for exploting data where more people have access. As a result your data will have greater value when it is open (to see how see below). Although you may have to share some of the pie with others, the overall pie (and so potentially your slice too) will be bigger.
This is particularly obvious for businesses who have ambitions for their data that are beyond their reach. It&rsquo;s clear that small businesses may not be able to afford a dedicated resource for data manipulation or scientific analysis. It&rsquo;s also true of larger organisations where the analysis is particularly complex and requires the skills of a specialist.
The notion of a network-effect actually goes a step further to argue that it&rsquo;s impossible for any individual business to realise the full potential of their data internally. The data has value for each person that uses it, and in turn each use increases the value of the data. This is because data doesn&rsquo;t hold a value <em>per se</em> &ndash; it&rsquo;s value is only realised when data is interpreted with context as information (i.e. when a datum is combined with another datum). If the openness is reciprocal (share-alike) then your data will increase in value as it is shared and linked with other sources. You may even reasonably expect to have your data corrected, cleaned, and maintained (reducing the cost of ownership). There is also the possiblity of other businesses being able to extract value with niche customisations that you don&rsquo;t have the interest (let alone the capacity or knowledge) to consider.
It should be apparent that this benefit is not guaranteed in all situations. If the pie doesn&rsquo;t get any bigger then there may be little to gain from sharing it. The likelihood is that it may be very hard to predict all possible avenues for exploiting your data. Further it&rsquo;s not certain, therefore that keeping data closed a precaution is prudent &ndash; it may turn out to be short-sighted&hellip;</p>

<h3>Risk mitigation &ndash; Open it or else</h3>

<p>If you don&rsquo;t open it, your competitors will.
The value of information depends upon it revealing something novel. Since there are usually a variety of ways of answering a given question it&rsquo;s likely that your data is not entirely unique (i.e. for every purpose, and every user). As a result you stand to be undermined by a competitor who is willing to offer alternative (although not necessarily completely substitutable) data at a lower price. Economic theory suggests that, in competitive markets, the price will equal the marginal cost of supply. Since the marginal cost of supplying data is effectively 0 (or at least very low), you may well find yourself undercut by an open data provider. You are only insulated from this risk to the extent that alternative sources are not perfect substitutes for your data from the perspective of your customers and markets.
Again, this risk is not certain. If you have the sole provider of a data source for which there are no direct substitutes then the probability of being undercut is lower. By exploiting this monopolistic position, however, you leave tremendous incentives for others to find imaginative alternatives to your offering. It may turn out that you&rsquo;re not as unique as you&rsquo;d assumed. Indeed there&rsquo;s no guarantee that you&rsquo;ll sustain the position of sole provider. Changing technology means that markets that were once protected by barriers to entry are now open to competition. If you are to operate an open data business model, however, and focus on a complementary service, then you are much more likely to cement your position as the default provider and retain your standing in the market&hellip;</p>

<h3>Reputation &ndash; Open is credible</h3>

<p>Opening data is a powerful means of being transparent. That transparency will make your propositions credibile by sending the signal that you have nothing to hide.
As has been particularly obvious in the food industry of late (for historians reading this blog in the next millenium we&rsquo;re in the middle of a crisis about eating horse meat that was advertised as beef), the complexity of global supply chains bring risks because provenance is hard to establish. Open data presents a solution to this problem.
This has to be genuine. Releasing data under the pretense of openness and at the same time making it difficult for anyone to interpret the data will be recognised as a cynical gesture.</p>

<h3>Attention &ndash; Open is attractive</h3>

<p>Where data is opened in an easily accessible format with some guarantee that the openness will be sustained, it will gather a lot of attention. A captive audience is certainly a valuable asset. The traffic it generates may be more valuable than the data itself. The technical implementation must be thought through carefully if the attention is going to be captured/ channeled through this approach.</p>

<h2>Using Open Data</h2>

<p>There are a variety of ways to profit from open data. The line-between this categories is blurred. The general sequence is from data source to final use. Applications may include one or more steps.</p>

<ul>
<li>Enabling Infrastructural</li>
<li>Information Enrichment</li>
<li>Analysis and Consultancy</li>
<li>Application Development</li>
</ul>


<h3>Enabling Infrastructure</h3>

<p>Although open data ought to be free to access it may not be free to enable that access. There is a cost (and therefore a profit) associated with opening data. A business or a government agency who wishes to open their a data are customers in this regard. Thus there is a business opportunity in supplying services such as:</p>

<ul>
<li>Information architecture design &ndash; planning out the schema, ontology, or technical implementation details for open data (either as a service or as creation of an open meta-data asset);</li>
<li>Database &ndash; the technology that will hold the data;</li>
<li>Web hosting &ndash; the technology that will open-up access to the data;</li>
<li>Service/ Application layer &ndash; the technology that will make it (re)usable: Linked-open data, indexing services, user interfaces, APIs, integration gateways, data loaders etc (note that I&rsquo;m thinking particularly of just the server-side &lsquo;openning&rsquo; bit here, not client-side applications of open data &ndash; that comes next!);</li>
<li>Advice on Licensing &ndash; the legal framework; and</li>
<li>Business Advice on Strategy &ndash; as per this post!</li>
</ul>


<h3>Information Enrichment</h3>

<p>As we have seen, data is valuable when presented in context as information. There is a value then, in enriching data by adding more data or context. Some ideas for what this might look like are shared below. The general distinction about enrichment I&rsquo;ve made is that it stops short of being analysis (i.e. the output of enrichment is more open data, not conclusions or decisions &ndash; see the following section for that).
Enrichment services might include:</p>

<ul>
<li>Linking-open data sources (tying a dataset into the semantic web)</li>
<li>Quality assurance &ndash; providing an independent certification or compliance service (must be careful to consider who pays/ scrutinises for the sake of credibility)</li>
<li>Text analysis &ndash; information extraction (entity recognition, annotation)</li>
<li>Cleaning data &ndash; e.g. reconciling duplicates, ensuring consistency, identifying junk data, processing data so that it conforms with an objective standard)</li>
<li>Reformating &ndash; i.e. tranforming data so that it&rsquo;s provided in a more useful (typically machine readable) format e.g. translating pdfs into csv, wrapping a database in an API</li>
</ul>


<h3>Analysis and Consultancy</h3>

<p>Open data can be a vital input into services designed to provide advice and support to decision makers. Beyond the simple fact that the information is free, there is a value in using a resource that is open because it is verifiable. That is to say, your analysis may be reproduced and checked. Notice that this doesn&rsquo;t actually need to have happened for this to be of benefit, indeed the very possibility may be credible enough.
For the sake of completeness here are some examples of analytical services that might benefit from using open data sources:</p>

<ul>
<li>Consultancy/ Advice/ Decision support/ Insight</li>
<li>Policy Development/ Advocacy/ Lobbying</li>
<li>Statistical analysis and modelling</li>
<li>Presentation (data graphics/ visualisation, sonification, and interaction)</li>
<li>Scientific, Technical or Operational research (and product or process development)</li>
</ul>


<h3>Application Development</h3>

<p>Finally open data can be integrated into applications that provide value to consumers, businesses, government, or indeed other developers. Here open data is interpreted in a particular domain of interest to provide a service.</p>

<h2>Commercial models for Open Data</h2>

<p>So we&rsquo;ve seen the value of openning data, and of using open data, but how can this value be translated into profit? Here I&rsquo;ll present a few models:</p>

<ul>
<li>normal pricing</li>
<li>cross-subsidy</li>
<li>freemium</li>
<li>advertising</li>
<li>sponsorship</li>
<li>affiliation</li>
</ul>


<h3>Normal pricing</h3>

<p>The most obvious model is &lsquo;normal&rsquo; pricing. This bears stating as it&rsquo;s not always apparent from listening to open data advocates! Just because the data is provided for free, it doesn&rsquo;t mean that the services that apply this data must be provided for free. Your ability to charge for something will depend upon how costly it would be for another person (or business) to reproduce the application you&rsquo;ve created.
Traditional pricing models are also part of&hellip;</p>

<h3>Cross-subsidy</h3>

<p>The idea here is that an open data proposition enhances the value of complementary services to the extent that those other services make enough extra profit to pay for the costs of openning the data. Clearly this is easiest where the organisation that decides to open the data is also the one generating profit from the service although it may be possible to design commercial arrangements for a payment between two organisations.
The inherent difficulty with this model is problem of quantifying the contribution of the open data to the complementary service. Since open data is untraded and thus there&rsquo;s no price signal of value. While it may be possible to calculate the total value of network effects captured by a given organisation, it is particularly difficult to put a price on the risk avoidance or reputational benefits.</p>

<h3>Freemium</h3>

<p>Where the service is the provision of data itself it&rsquo;s not possible to follow either of the first two models. As such an alternative is to segment the market &ndash; providing a basic level of &lsquo;free&rsquo; service and a premium level of &lsquo;paid&rsquo; service (essentially a cross-subsidy from the latter to the former). This can operate like a loss-leader. Typically the market is segmented according to the level of access provided (number or range of requests permitted or the speed of response). As the premium services begin to differ systematically from the core open data offering (e.g. training or consultancy) this pricing model begins to ressemble the cross-subsidy archetype.</p>

<h3>Advertising</h3>

<p>This is the most generally-applicable of the pricing models. Where a cross-subsidy cannot be established (perhaps because the difficulty agreeing a contract between the data opener and service vendor) it may be possible to pay for open data via advertising.</p>

<h3>Sponsorship</h3>

<p>If your data generates enough attention, people may be willing to pay you to include their content. Naturally this isn&rsquo;t an obvious option for a start-up or un-tested service and it may be inappropriate for some data sets. For example: sponsored links on Twitter, Google Search and Reddit.</p>

<h3>Affiliation</h3>

<p>This is the reverse side of sponsorship where affiliates receive open data for free which they then process and redistribute in order to send attention back up the chain. For example: Amazon.</p>

<h2>Further information&hellip;</h2>

<p>If you want to find out more then you might like to check out these links:</p>

<ul>
<li><a href="http://www.slideshare.net/OpeningUp/open-data-conference-john-sheridan-open-data-as-an-operating-model">Open Data as an Operating Model</a> &ndash; John Sheridan explains how a linked-open-data approach enabled a mutually beneficial ecosystem around legislation.gov.uk. Check out slides 17, 24, and 33 in particular &ndash; they should you how the pieces fit together.</li>
<li><a href="http://chiefmartec.com/2010/01/7-business-models-for-linked-data/">7 Business Models for Linked Data</a> &ndash; Scott Brinker provides some far more catchy labels for these ideas than I have! <em>Data-layer ads</em>?!</li>
<li><a href="http://blog.ldodds.com/2010/01/10/thoughts-on-linked-data-business-models/">Thoughts on Linked Data Business Models</a> &ndash; Leigh Dodds provides some insights into how Scott&rsquo;s ideas might be implemented and also comments on a motive I&rsquo;ve overlooked here &ndash; philanthropy!</li>
<li><a href="http://www.scribd.com/doc/124951288/The-business-of-Open-Data-where-s-the-benefit">The Business of Open Data &ndash; Where&rsquo;s the Benefit</a> and <a href="https://soundcloud.com/theodi/odi-fridays-the-business-of">the accompanying audio track</a> &ndash; Jeni Tenison provides a contrast of a few models (including the closed data case) with the help of Osterwalder&rsquo;s Business Model Canvas.</li>
</ul>


<p>If that&rsquo;s not enough then you might be interested in attending a workshop on the <a href="http://futureeverything.org/summit/conference/business-of-open-data-workshop/">Business of Open Data</a> that&rsquo;s taking place as part of this year&rsquo;s <a href="http://futureeverything.org/">Future Everything Summit of Ideas &amp; Digtial Invention</a>.</p>

<p>Indeed if you&rsquo;re in Manchester why not pop along to the next <a href="http://opendatamanchester.org.uk/">Open Data Manchester</a>?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[3 Metrics for Heath Economics Analysis]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2012/12/19/3-metrics-for-heath-economics-analysis/"/>
    <updated>2012-12-19T16:43:00+00:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2012/12/19/3-metrics-for-heath-economics-analysis</id>
    <content type="html"><![CDATA[<p>I&rsquo;m often asked to suggest measures for assessing health interventions from an economic perspective. Here are explanations of four commonly used analytical methods:</p>

<ul>
<li>Reduction in Costs of Treatment</li>
<li>Cost per Quality Adjusted Life Years (QALY)</li>
<li>Incremental Cost Effectiveness Ratio (ICER)</li>
</ul>


<!--more-->


<p>As should be obvious from the titles, cost plays a significance role in health economics analysis. The first measure considers cost directly. The second measures also incorporate utility or benefit. The final measure should be used for interpretation.</p>

<p>In practice, it&rsquo;s advisable to consider using more than one method to account for the limitations of individual measures. It&rsquo;s also important to control for demographic and socio-economic characteristics such as age, gender, ethnicity, employment, and health condition. It will also be insightful to consider location as a proxy indicator for a range of (highly-correlated) socio-economic characteristics.</p>

<h2>Reduction in costs of treatment</h2>

<p>This is the most easily understandable economic impact of health interventions. If preventive steps are taken, fewer people contract disease, and less will need to be spent on treatment. The main focus of research under this measure is in <strong>quantifying the intervention&rsquo;s impact on health and the cost of treatment that is obviated</strong>. Weight loss, for example, will reduce the relative risk of diabetes and cardio-vascual disease. The relationship between intervention and disease risk might be established by reference to physiological measures (such as Body Mass Index). Cost of treatment might include the cost of prescription medicine, GP consultation, surgery and palliative care.</p>

<p>The difficulty with this sort of measure is that the impact is stated in terms of money that would otherwise have had to be spent and, as such, is quite intangigble.</p>

<h2>Cost per QALY</h2>

<p>A quality adjusted-life year, or QALY, represents <strong>the number of years of life that would be added by an intervention, taking into account the quality of those years</strong>. If the extra years would not be lived in full health they are given a value less than 1. Clearly the method of adjustment for quality is critical to this metric.
A commonly adopted measure is the <a href="http://www.euroqol.org/">EQ-5D</a> scale which seeks to categorise health states according to 5 dimensions: mobility, self-care, usual activities, pain/ discomfort and anxiety/ depression. This is combined with a quantiative measure of the patients self-assessment of their health on a <em>vertical analogue scale</em>.
Other approaches include the <em>time trade-off</em>, where respondents are asked to choose between remaining in an ill state or being restored to perfect health with a shorter life expectancy, and <em>standard gamble</em> where the alternative could restore them to perfect health or kill them.
This measure is criticised due to the difficulty of establishing a meaningful, objective, and comparable definition of &ldquo;perfect health&rdquo; and &ldquo;disease burden&rdquo;.</p>

<h2>Incremental Cost-Effectiveness Ratio</h2>

<p>This ratio is used for comparing intervention options on a like for like basis. The Incremental Cost Effectiveness Ratio (ICER) is a <strong>comparison of the relative cost per QALY of the intervention and a reference case</strong> as follows (where QALY refers to a Quality Adjusted Life Year):
$$
ICER = \frac{ \text{£ Cost of intervention} &ndash; \text{£ Cost of reference case} } { \text{QALY Effect of intervention} –  \text{QALY Effect of reference case} }
$$
The ICER assumes a multiplicative model for QALYs (i.e. a change in scale will change the ICER ratio even though original figures remain the same).
Benchmarking against other interventions provides valuable contextual information. The <a href="https://research.tufts-nemc.org/cear4/default.aspx">Tufts Cost-Effectiveness Analysis Registry</a> is a valuable resource in this regard.</p>

<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Economics of Open Data]]></title>
    <link href="http://infonomics.ltd.uk/news/blog/2012/10/25/the-economics-of-open-data/"/>
    <updated>2012-10-25T15:35:00+01:00</updated>
    <id>http://infonomics.ltd.uk/news/blog/2012/10/25/the-economics-of-open-data</id>
    <content type="html"><![CDATA[<p>Data doesn&rsquo;t make for a very good tradable commodity. Technological changes that allow us to connect and share data more easily are disrupting established business models. Therefore the public sector has a critical role to intervene in the data market and the private sector must adapt to ensure long-term sustainability.</p>

<!--more-->


<h2>The Market Isn&rsquo;t Always Perfect</h2>

<p>Economists use this term to describe situations where the allocation of goods and services by the free market is inefficient (i.e. someone can be made better off without making another worse off). <strong>In some extreme cases the good or service would not be available without intervention by government</strong>. The market is only effective if the good or service:</p>

<ul>
<li>has a price which reflects all costs and benefits</li>
<li>can be withheld from people at reasonable expense</li>
<li>cannot be used by more than one person at the same time</li>
</ul>


<p>These characteristics don&rsquo;t apply in the case of open data&hellip;</p>

<h2>Open Data: The Gift That Keeps On Giving</h2>

<p>An externality, or spillover effect, is a cost or benefit that is incurred by someone who is not involved in the trade. The price will not reflect these indirect social impacts. Pollution is an example of how external costs can lead to excessive production.</p>

<p><em>Network externalities</em> are a form of external benefit. Within a network the value of an adding an extra node or edge (e.g. person or friendship) is felt by every other part of the network. The Metrolink extension, for example, is not only of benefit to people in the new areas that can now use trams, but also to people in the existing areas that can now access new areas.</p>

<p>Network externalities occur in the case of open data because data is only informative when it is interpreted. The value of each datum increases with the volume of other data that it may be connected with as the context and range of analysis that are possible increases. Thus, data operates as a network. In deciding whether or not to open their data, <strong>private organisations will not consider the indirect benefits that their data will have to improve the quality of every other dataset</strong> and so will release less data than is socially optimal.</p>

<h2>Data As A Public Good</h2>

<p>A <em>public good</em> is one which is non-excludable (impossible to prevent people from using it) and non-rival (one person&rsquo;s use doesn&rsquo;t not reduce availability to another). The problem with these goods is that consumers can take advantage without contributing sufficiently to their creation. If too many people decide to <em>free-ride</em> then the private revenues won&rsquo;t meet the private costs and the incentive to provide the good through the market will disappear.</p>

<p>Data is typically non-excludable. Although legislation may prohibit the buyer from sharing data it is, in many cases, practically unenforcable (as is apparent with music sharing, for example). Data is also non-rival. Your reading of this post does not prevent another person from reading it &ndash; indeed I don&rsquo;t loose the ideas when I write them down &ndash; we can all enjoy them at the same time. <strong>Where data may be characterised as a public good, subject to the free-rider problem, there won&rsquo;t be sufficient private incentives for production and distribution</strong>.</p>

<h2>Implications For Business &amp; Government</h2>

<p>So what does this economic analysis tell us?</p>

<ol>
<li>Technological change (particularly the increasing capacity for connecting and sharing data) will disrupt certain markets by undermining established closed-data business models;</li>
<li>Businesses that attempt to defend outdated business models by keeping data closed won&rsquo;t be able to compete with an open alternatives (alternatives that they are encouraging by keeping their data closed);</li>
<li>It&rsquo;s probably better for such businesses to open their data before a competitor does &ndash; they shouldn&rsquo;t waste their current position of dominance;</li>
<li>In some cases, where the market fails completely, public intervention to fund the creation or provision of information will help to improve economic growth and social welfare;</li>
<li>In other cases there will be considerable <a href="/blog/2013/03/01/open-data-business-models/">opportunities for private firms to innovate and capture the benefits of open data</a>.</li>
</ol>

]]></content>
  </entry>
  
</feed>
